{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D\n",
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "#from keras.utils.vis_utils import model_to_dot\n",
    "#from keras.utils import plot_model\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly import tools\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "\n",
    "from IPython.display import Image\n",
    "import glob\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_val\\\\100_1_0_20170112215032192.jpg.chip.jpg',\n",
       " 'train_val\\\\100_1_2_20170112213615815.jpg.chip.jpg',\n",
       " 'train_val\\\\10_0_0_20161220222308131.jpg.chip.jpg',\n",
       " 'train_val\\\\10_1_0_20170109203245653.jpg.chip.jpg',\n",
       " 'train_val\\\\116_1_3_20170120134744096.jpg.chip.jpg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_Path = 'train_val/'\n",
    "\n",
    "files = list(glob.glob(my_Path+'*.jpg'))\n",
    "files\n",
    "len(files)\n",
    "files[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(files[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHEKHAR\\AppData\\Local\\Temp\\ipykernel_16508\\3067218790.py:3: FutureWarning:\n",
      "\n",
      "Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'True' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('df.csv', index_col= 0)\n",
    "\n",
    "df.loc[df['Gender'] == 1, 'Gender'] = True\n",
    "df.loc[df['Gender'] == 0, 'Gender'] = False\n",
    "\n",
    "                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_0</th>\n",
       "      <th>p_1</th>\n",
       "      <th>p_2</th>\n",
       "      <th>p_3</th>\n",
       "      <th>p_4</th>\n",
       "      <th>p_5</th>\n",
       "      <th>p_6</th>\n",
       "      <th>p_7</th>\n",
       "      <th>p_8</th>\n",
       "      <th>p_9</th>\n",
       "      <th>...</th>\n",
       "      <th>p_49144</th>\n",
       "      <th>p_49145</th>\n",
       "      <th>p_49146</th>\n",
       "      <th>p_49147</th>\n",
       "      <th>p_49148</th>\n",
       "      <th>p_49149</th>\n",
       "      <th>p_49150</th>\n",
       "      <th>p_49151</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>85</td>\n",
       "      <td>89</td>\n",
       "      <td>94</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>151</td>\n",
       "      <td>173</td>\n",
       "      <td>154</td>\n",
       "      <td>152</td>\n",
       "      <td>174</td>\n",
       "      <td>155</td>\n",
       "      <td>152</td>\n",
       "      <td>178</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>236</td>\n",
       "      <td>231</td>\n",
       "      <td>197</td>\n",
       "      <td>191</td>\n",
       "      <td>184</td>\n",
       "      <td>149</td>\n",
       "      <td>142</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 49154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   p_0  p_1  p_2  p_3  p_4  p_5  p_6  p_7  p_8  p_9  ...  p_49144  p_49145  \\\n",
       "0   14   16   17   34   37   41   85   89   94  117  ...       32       30   \n",
       "1  154  151  173  154  152  174  155  152  178  152  ...      236      231   \n",
       "\n",
       "   p_49146  p_49147  p_49148  p_49149  p_49150  p_49151  Gender  Age  \n",
       "0       21       29       28        7       15       14       1   99  \n",
       "1      197      191      184      149      142      133       0   87  \n",
       "\n",
       "[2 rows x 49154 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X   = df.drop(['Age', 'Gender'], axis = 1)\n",
    "y = df['Gender']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_rows = 128\n",
    "image_cols = 128\n",
    "batch_size = 4096\n",
    "\n",
    "\n",
    "image_shape = (image_rows,image_cols,3)\n",
    "train_data = np.array(X_train, dtype = 'float32')\n",
    "test_data = np.array(X_test, dtype='float32')\n",
    "\n",
    "\n",
    "#x_validate = x_validate.reshape(x_validate.shape[0],*image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49152"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[103., 103.,  97., ...,  41.,  28.,  26.],\n",
       "       [ 93.,  92., 131., ...,  58.,  13.,   2.],\n",
       "       [ 64.,  99., 142., ...,  88., 123., 167.],\n",
       "       ...,\n",
       "       [ 62.,  78., 121., ..., 143., 147., 165.],\n",
       "       [ 99., 160., 192., ..., 201., 201., 201.],\n",
       "       [ 87.,  96.,  99., ...,  75.,  88., 126.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data/255\n",
    "\n",
    "x_test= test_data/255\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],*image_shape)\n",
    "x_test = x_test.reshape(x_test.shape[0],*image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.40392157, 0.40392157, 0.38039216],\n",
       "         [0.3764706 , 0.3764706 , 0.3529412 ],\n",
       "         [0.3882353 , 0.39215687, 0.3764706 ],\n",
       "         ...,\n",
       "         [0.68235296, 0.65882355, 0.6313726 ],\n",
       "         [0.61960787, 0.58431375, 0.5686275 ],\n",
       "         [0.52156866, 0.4862745 , 0.47058824]],\n",
       "\n",
       "        [[0.40392157, 0.40392157, 0.38039216],\n",
       "         [0.39607844, 0.39607844, 0.37254903],\n",
       "         [0.40392157, 0.40784314, 0.39215687],\n",
       "         ...,\n",
       "         [0.6745098 , 0.6509804 , 0.62352943],\n",
       "         [0.63529414, 0.6       , 0.58431375],\n",
       "         [0.5568628 , 0.52156866, 0.5058824 ]],\n",
       "\n",
       "        [[0.40392157, 0.40392157, 0.38039216],\n",
       "         [0.41960785, 0.41960785, 0.39607844],\n",
       "         [0.42352942, 0.42745098, 0.4117647 ],\n",
       "         ...,\n",
       "         [0.65882355, 0.63529414, 0.60784316],\n",
       "         [0.64705884, 0.62352943, 0.6039216 ],\n",
       "         [0.6039216 , 0.5803922 , 0.56078434]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8980392 , 0.81960785, 0.7490196 ],\n",
       "         [0.94509804, 0.8666667 , 0.79607844],\n",
       "         [0.96862745, 0.8862745 , 0.8039216 ],\n",
       "         ...,\n",
       "         [0.16078432, 0.10980392, 0.10196079],\n",
       "         [0.16078432, 0.10980392, 0.10196079],\n",
       "         [0.16470589, 0.11372549, 0.10588235]],\n",
       "\n",
       "        [[0.8235294 , 0.74509805, 0.6784314 ],\n",
       "         [0.9137255 , 0.8352941 , 0.7647059 ],\n",
       "         [0.9411765 , 0.8666667 , 0.78431374],\n",
       "         ...,\n",
       "         [0.16078432, 0.10980392, 0.10196079],\n",
       "         [0.16078432, 0.10980392, 0.10196079],\n",
       "         [0.16078432, 0.10980392, 0.10196079]],\n",
       "\n",
       "        [[0.7607843 , 0.68235296, 0.6156863 ],\n",
       "         [0.88235295, 0.8039216 , 0.73333335],\n",
       "         [0.9254902 , 0.84705883, 0.7764706 ],\n",
       "         ...,\n",
       "         [0.16078432, 0.10980392, 0.10196079],\n",
       "         [0.16078432, 0.10980392, 0.10196079],\n",
       "         [0.16078432, 0.10980392, 0.10196079]]],\n",
       "\n",
       "\n",
       "       [[[0.3647059 , 0.36078432, 0.5137255 ],\n",
       "         [0.3019608 , 0.29803923, 0.4509804 ],\n",
       "         [0.21568628, 0.21176471, 0.3647059 ],\n",
       "         ...,\n",
       "         [0.30980393, 0.34509805, 0.5176471 ],\n",
       "         [0.3137255 , 0.33333334, 0.50980395],\n",
       "         [0.32156864, 0.34509805, 0.5137255 ]],\n",
       "\n",
       "        [[0.30980393, 0.30588236, 0.45882353],\n",
       "         [0.25882354, 0.25490198, 0.40784314],\n",
       "         [0.20392157, 0.2       , 0.3529412 ],\n",
       "         ...,\n",
       "         [0.30980393, 0.33333334, 0.50980395],\n",
       "         [0.3019608 , 0.32156864, 0.49803922],\n",
       "         [0.30980393, 0.33333334, 0.5019608 ]],\n",
       "\n",
       "        [[0.25882354, 0.25490198, 0.4117647 ],\n",
       "         [0.22352941, 0.21960784, 0.3764706 ],\n",
       "         [0.2       , 0.19607843, 0.3529412 ],\n",
       "         ...,\n",
       "         [0.3019608 , 0.3254902 , 0.5019608 ],\n",
       "         [0.28627452, 0.30588236, 0.48235294],\n",
       "         [0.28627452, 0.30980393, 0.47843137]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5372549 , 0.6666667 , 0.84313726],\n",
       "         [0.5372549 , 0.6666667 , 0.84313726],\n",
       "         [0.54901963, 0.67058825, 0.84705883],\n",
       "         ...,\n",
       "         [0.22745098, 0.05098039, 0.00784314],\n",
       "         [0.22745098, 0.05098039, 0.00784314],\n",
       "         [0.22745098, 0.05098039, 0.00784314]],\n",
       "\n",
       "        [[0.54901963, 0.6784314 , 0.85490197],\n",
       "         [0.54901963, 0.6784314 , 0.85490197],\n",
       "         [0.56078434, 0.6784314 , 0.8627451 ],\n",
       "         ...,\n",
       "         [0.22745098, 0.05098039, 0.00784314],\n",
       "         [0.22745098, 0.05098039, 0.00784314],\n",
       "         [0.22745098, 0.05098039, 0.00784314]],\n",
       "\n",
       "        [[0.54509807, 0.6745098 , 0.8509804 ],\n",
       "         [0.54901963, 0.6784314 , 0.85490197],\n",
       "         [0.5568628 , 0.6745098 , 0.85882354],\n",
       "         ...,\n",
       "         [0.22745098, 0.05098039, 0.00784314],\n",
       "         [0.22745098, 0.05098039, 0.00784314],\n",
       "         [0.22745098, 0.05098039, 0.00784314]]],\n",
       "\n",
       "\n",
       "       [[[0.2509804 , 0.3882353 , 0.5568628 ],\n",
       "         [0.28627452, 0.42352942, 0.5921569 ],\n",
       "         [0.30588236, 0.45490196, 0.61960787],\n",
       "         ...,\n",
       "         [0.19607843, 0.3529412 , 0.54509807],\n",
       "         [0.19215687, 0.34901962, 0.5529412 ],\n",
       "         [0.19215687, 0.34901962, 0.5529412 ]],\n",
       "\n",
       "        [[0.2509804 , 0.3882353 , 0.5568628 ],\n",
       "         [0.28627452, 0.42352942, 0.5921569 ],\n",
       "         [0.30588236, 0.45490196, 0.61960787],\n",
       "         ...,\n",
       "         [0.20392157, 0.36078432, 0.5529412 ],\n",
       "         [0.19607843, 0.3529412 , 0.5568628 ],\n",
       "         [0.19215687, 0.34901962, 0.5529412 ]],\n",
       "\n",
       "        [[0.25490198, 0.39215687, 0.56078434],\n",
       "         [0.2901961 , 0.42745098, 0.59607846],\n",
       "         [0.31764707, 0.45490196, 0.62352943],\n",
       "         ...,\n",
       "         [0.21960784, 0.3764706 , 0.5686275 ],\n",
       "         [0.20392157, 0.36078432, 0.5647059 ],\n",
       "         [0.19607843, 0.3529412 , 0.5568628 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.2       , 0.34901962, 0.5372549 ],\n",
       "         [0.1764706 , 0.32941177, 0.5058824 ],\n",
       "         [0.16078432, 0.3019608 , 0.48235294],\n",
       "         ...,\n",
       "         [0.3529412 , 0.4862745 , 0.6666667 ],\n",
       "         [0.36078432, 0.49803922, 0.67058825],\n",
       "         [0.36078432, 0.49803922, 0.67058825]],\n",
       "\n",
       "        [[0.1764706 , 0.33333334, 0.5254902 ],\n",
       "         [0.15686275, 0.3137255 , 0.5019608 ],\n",
       "         [0.15294118, 0.30588236, 0.48235294],\n",
       "         ...,\n",
       "         [0.35686275, 0.49019608, 0.67058825],\n",
       "         [0.36078432, 0.49803922, 0.67058825],\n",
       "         [0.3529412 , 0.49019608, 0.6627451 ]],\n",
       "\n",
       "        [[0.16470589, 0.32156864, 0.5137255 ],\n",
       "         [0.14901961, 0.30588236, 0.49411765],\n",
       "         [0.14901961, 0.29803923, 0.4862745 ],\n",
       "         ...,\n",
       "         [0.35686275, 0.49019608, 0.67058825],\n",
       "         [0.35686275, 0.49411765, 0.6666667 ],\n",
       "         [0.34509805, 0.48235294, 0.654902  ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.24313726, 0.30588236, 0.4745098 ],\n",
       "         [0.2784314 , 0.34117648, 0.50980395],\n",
       "         [0.3372549 , 0.4       , 0.5686275 ],\n",
       "         ...,\n",
       "         [0.5764706 , 0.6313726 , 0.7058824 ],\n",
       "         [0.57254905, 0.627451  , 0.7019608 ],\n",
       "         [0.5686275 , 0.62352943, 0.69803923]],\n",
       "\n",
       "        [[0.29411766, 0.35686275, 0.5254902 ],\n",
       "         [0.3254902 , 0.3882353 , 0.5568628 ],\n",
       "         [0.38039216, 0.44313726, 0.6117647 ],\n",
       "         ...,\n",
       "         [0.5764706 , 0.6313726 , 0.7058824 ],\n",
       "         [0.57254905, 0.627451  , 0.7019608 ],\n",
       "         [0.5686275 , 0.62352943, 0.69803923]],\n",
       "\n",
       "        [[0.34901962, 0.4117647 , 0.5803922 ],\n",
       "         [0.3764706 , 0.4392157 , 0.60784316],\n",
       "         [0.42352942, 0.4862745 , 0.654902  ],\n",
       "         ...,\n",
       "         [0.5764706 , 0.6313726 , 0.7058824 ],\n",
       "         [0.57254905, 0.627451  , 0.7019608 ],\n",
       "         [0.5686275 , 0.62352943, 0.69803923]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.6431373 , 0.7019608 , 0.9882353 ],\n",
       "         [0.60784316, 0.6666667 , 0.9529412 ],\n",
       "         [0.54901963, 0.6039216 , 0.9019608 ],\n",
       "         ...,\n",
       "         [0.5372549 , 0.5568628 , 0.6156863 ],\n",
       "         [0.54509807, 0.56078434, 0.6313726 ],\n",
       "         [0.5529412 , 0.5686275 , 0.6392157 ]],\n",
       "\n",
       "        [[0.627451  , 0.68235296, 0.98039216],\n",
       "         [0.6039216 , 0.65882355, 0.95686275],\n",
       "         [0.5686275 , 0.62352943, 0.92156863],\n",
       "         ...,\n",
       "         [0.54509807, 0.56078434, 0.6313726 ],\n",
       "         [0.54901963, 0.5647059 , 0.63529414],\n",
       "         [0.5568628 , 0.57254905, 0.6431373 ]],\n",
       "\n",
       "        [[0.6117647 , 0.6666667 , 0.9647059 ],\n",
       "         [0.6       , 0.654902  , 0.9529412 ],\n",
       "         [0.5764706 , 0.6313726 , 0.92941177],\n",
       "         ...,\n",
       "         [0.54901963, 0.5647059 , 0.63529414],\n",
       "         [0.5529412 , 0.5686275 , 0.6392157 ],\n",
       "         [0.56078434, 0.5764706 , 0.64705884]]],\n",
       "\n",
       "\n",
       "       [[[0.3882353 , 0.627451  , 0.7529412 ],\n",
       "         [0.39215687, 0.627451  , 0.74509805],\n",
       "         [0.41568628, 0.627451  , 0.74509805],\n",
       "         ...,\n",
       "         [0.6666667 , 0.7254902 , 0.8       ],\n",
       "         [0.64705884, 0.70980394, 0.8       ],\n",
       "         [0.6431373 , 0.7058824 , 0.79607844]],\n",
       "\n",
       "        [[0.3882353 , 0.627451  , 0.7529412 ],\n",
       "         [0.39215687, 0.627451  , 0.74509805],\n",
       "         [0.4117647 , 0.6313726 , 0.74509805],\n",
       "         ...,\n",
       "         [0.6666667 , 0.7254902 , 0.8       ],\n",
       "         [0.64705884, 0.70980394, 0.8       ],\n",
       "         [0.6431373 , 0.7058824 , 0.79607844]],\n",
       "\n",
       "        [[0.38039216, 0.627451  , 0.7607843 ],\n",
       "         [0.38039216, 0.61960787, 0.74509805],\n",
       "         [0.40392157, 0.627451  , 0.7490196 ],\n",
       "         ...,\n",
       "         [0.67058825, 0.7294118 , 0.8039216 ],\n",
       "         [0.6509804 , 0.7137255 , 0.8039216 ],\n",
       "         [0.6431373 , 0.7058824 , 0.79607844]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.91764706, 0.9372549 , 0.93333334],\n",
       "         [0.9254902 , 0.94509804, 0.9411765 ],\n",
       "         [0.9411765 , 0.9490196 , 0.9490196 ],\n",
       "         ...,\n",
       "         [0.8117647 , 0.8117647 , 0.8117647 ],\n",
       "         [0.8       , 0.8       , 0.8       ],\n",
       "         [0.7921569 , 0.7921569 , 0.7921569 ]],\n",
       "\n",
       "        [[0.9137255 , 0.93333334, 0.92941177],\n",
       "         [0.92156863, 0.9411765 , 0.9372549 ],\n",
       "         [0.9372549 , 0.94509804, 0.94509804],\n",
       "         ...,\n",
       "         [0.7921569 , 0.7921569 , 0.7921569 ],\n",
       "         [0.78431374, 0.78431374, 0.78431374],\n",
       "         [0.7882353 , 0.7882353 , 0.7882353 ]],\n",
       "\n",
       "        [[0.9098039 , 0.92941177, 0.9254902 ],\n",
       "         [0.91764706, 0.9372549 , 0.93333334],\n",
       "         [0.9372549 , 0.94509804, 0.94509804],\n",
       "         ...,\n",
       "         [0.78039217, 0.78039217, 0.78039217],\n",
       "         [0.78039217, 0.78039217, 0.78039217],\n",
       "         [0.7882353 , 0.7882353 , 0.7882353 ]]],\n",
       "\n",
       "\n",
       "       [[[0.34117648, 0.3764706 , 0.3882353 ],\n",
       "         [0.33333334, 0.36862746, 0.38431373],\n",
       "         [0.33333334, 0.37254903, 0.4       ],\n",
       "         ...,\n",
       "         [0.17254902, 0.23529412, 0.41568628],\n",
       "         [0.1882353 , 0.25490198, 0.42352942],\n",
       "         [0.21176471, 0.2784314 , 0.44705883]],\n",
       "\n",
       "        [[0.33333334, 0.36862746, 0.38039216],\n",
       "         [0.31764707, 0.36078432, 0.3764706 ],\n",
       "         [0.32941177, 0.36862746, 0.39607844],\n",
       "         ...,\n",
       "         [0.19215687, 0.25490198, 0.43529412],\n",
       "         [0.1882353 , 0.2509804 , 0.43137255],\n",
       "         [0.2       , 0.26666668, 0.43529412]],\n",
       "\n",
       "        [[0.31764707, 0.3647059 , 0.37254903],\n",
       "         [0.3137255 , 0.35686275, 0.37254903],\n",
       "         [0.32941177, 0.36862746, 0.39607844],\n",
       "         ...,\n",
       "         [0.21568628, 0.2784314 , 0.45882353],\n",
       "         [0.19607843, 0.25882354, 0.4392157 ],\n",
       "         [0.1882353 , 0.2509804 , 0.43137255]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.43529412, 0.41960785, 0.30588236],\n",
       "         [0.43137255, 0.41568628, 0.3019608 ],\n",
       "         [0.43137255, 0.41568628, 0.3019608 ],\n",
       "         ...,\n",
       "         [0.31764707, 0.3647059 , 0.5529412 ],\n",
       "         [0.30588236, 0.3529412 , 0.5176471 ],\n",
       "         [0.29411766, 0.34509805, 0.49411765]],\n",
       "\n",
       "        [[0.43529412, 0.41960785, 0.30588236],\n",
       "         [0.43137255, 0.41568628, 0.3019608 ],\n",
       "         [0.43137255, 0.41568628, 0.3019608 ],\n",
       "         ...,\n",
       "         [0.30980393, 0.35686275, 0.54509807],\n",
       "         [0.3019608 , 0.34901962, 0.5137255 ],\n",
       "         [0.29411766, 0.34509805, 0.49411765]],\n",
       "\n",
       "        [[0.43529412, 0.41960785, 0.30588236],\n",
       "         [0.43137255, 0.41568628, 0.3019608 ],\n",
       "         [0.43137255, 0.41568628, 0.3019608 ],\n",
       "         ...,\n",
       "         [0.30588236, 0.3529412 , 0.5411765 ],\n",
       "         [0.3019608 , 0.34901962, 0.5137255 ],\n",
       "         [0.29411766, 0.34509805, 0.49411765]]]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret optimizer identifier: <keras.src.optimizers.adam.Adam object at 0x000001CCDB6A3FA0>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 12\u001b[0m\n\u001b[0;32m      1\u001b[0m cnn_model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[0;32m      2\u001b[0m     Conv2D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m,input_shape \u001b[38;5;241m=\u001b[39m image_shape),\n\u001b[0;32m      3\u001b[0m     MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) ,\u001b[38;5;66;03m# down sampling the output instead of 28*28 it is 14*14\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \n\u001b[0;32m      9\u001b[0m ])\n\u001b[1;32m---> 12\u001b[0m \u001b[43mcnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbinary_crossentropy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbinary_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SHEKHAR\\.conda\\envs\\aws\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:568\u001b[0m, in \u001b[0;36mModel.compile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution, **kwargs)\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_compile(optimizer, metrics, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_eagerly \u001b[38;5;241m=\u001b[39m run_eagerly\n\u001b[1;32m--> 568\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_loss \u001b[38;5;241m=\u001b[39m compile_utils\u001b[38;5;241m.\u001b[39mLossesContainer(\n\u001b[0;32m    570\u001b[0m     loss, loss_weights, output_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_names)\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_metrics \u001b[38;5;241m=\u001b[39m compile_utils\u001b[38;5;241m.\u001b[39mMetricsContainer(\n\u001b[0;32m    572\u001b[0m     metrics, weighted_metrics, output_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_names,\n\u001b[0;32m    573\u001b[0m     from_serialized\u001b[38;5;241m=\u001b[39mfrom_serialized)\n",
      "File \u001b[1;32mc:\\Users\\SHEKHAR\\.conda\\envs\\aws\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:606\u001b[0m, in \u001b[0;36mModel._get_optimizer\u001b[1;34m(self, optimizer)\u001b[0m\n\u001b[0;32m    603\u001b[0m       opt \u001b[38;5;241m=\u001b[39m lso\u001b[38;5;241m.\u001b[39mLossScaleOptimizerV1(opt, loss_scale)\n\u001b[0;32m    604\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m opt\n\u001b[1;32m--> 606\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_get_single_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SHEKHAR\\.conda\\envs\\aws\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:628\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    544\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \n\u001b[0;32m    546\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m nest_util\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m    629\u001b[0m       nest_util\u001b[38;5;241m.\u001b[39mModality\u001b[38;5;241m.\u001b[39mCORE, func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    630\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\SHEKHAR\\.conda\\envs\\aws\\lib\\site-packages\\tensorflow\\python\\util\\nest_util.py:1065\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[0;32m    969\u001b[0m \n\u001b[0;32m    970\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[1;32m-> 1065\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_map_structure(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[0;32m   1067\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\SHEKHAR\\.conda\\envs\\aws\\lib\\site-packages\\tensorflow\\python\\util\\nest_util.py:1105\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m   1101\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[0;32m   1104\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m-> 1105\u001b[0m     [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m   1106\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[0;32m   1107\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\SHEKHAR\\.conda\\envs\\aws\\lib\\site-packages\\tensorflow\\python\\util\\nest_util.py:1105\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1100\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m   1101\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[0;32m   1104\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m-> 1105\u001b[0m     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m   1106\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[0;32m   1107\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\SHEKHAR\\.conda\\envs\\aws\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:597\u001b[0m, in \u001b[0;36mModel._get_optimizer.<locals>._get_single_optimizer\u001b[1;34m(opt)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_single_optimizer\u001b[39m(opt):\n\u001b[1;32m--> 597\u001b[0m   opt \u001b[38;5;241m=\u001b[39m \u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    598\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (loss_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    599\u001b[0m       \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(opt, lso\u001b[38;5;241m.\u001b[39mLossScaleOptimizer)):\n\u001b[0;32m    600\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss_scale \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\SHEKHAR\\.conda\\envs\\aws\\lib\\site-packages\\tensorflow\\python\\keras\\optimizers.py:127\u001b[0m, in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    125\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m deserialize(config)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    128\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not interpret optimizer identifier: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(identifier))\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret optimizer identifier: <keras.src.optimizers.adam.Adam object at 0x000001CCDB6A3FA0>"
     ]
    }
   ],
   "source": [
    "cnn_model = Sequential([\n",
    "    Conv2D(filters=32,kernel_size=3,activation='relu',input_shape = image_shape),\n",
    "    MaxPooling2D(pool_size=2) ,# down sampling the output instead of 28*28 it is 14*14\n",
    "    Dropout(0.2),\n",
    "    Flatten(), # flatten out the layers\n",
    "    Dense(32,activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "cnn_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
